{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Full.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"4PJ8MohpF1Ht","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import csv\n","import sys\n","import nltk\n","from nltk.corpus import stopwords\n","import glob\n","import os\n","import string"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKHimIdaF1Hy","colab_type":"code","outputId":"ace05c3c-6a8d-4ec0-8db9-6e016f161f7c","colab":{}},"source":["#Load training file\n","\n","text_file = open(\"train1.ft.txt\", \"r\", encoding=\"utf8\")\n","lines = text_file.read().split('\\n')\n","\n","labels = []\n","for item in lines:\n","    first_four_letters = item[:10]\n","    if first_four_letters == '__label__1':\n","        labels.append(int(1))\n","    else:\n","        labels.append(int(2))\n","        \n","def remove_label(s):\n","    return s[11:]\n","lines = [remove_label(s) for s in lines]\n","\n","df = pd.DataFrame()\n","df['text'] = lines\n","df['label'] = labels\n","\n","df = df.sample(120000)\n","print(len(df))\n","df.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["120000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3265217</th>\n","      <td>JUNK / Bad Seller!!: I paid $7.63 for this ite...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3207238</th>\n","      <td>An awesome book by a wonderful author: I met L...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1359854</th>\n","      <td>Too small and awkward: While cute, this little...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1715468</th>\n","      <td>Very enjoyable: Feels like I've spent a month ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2670191</th>\n","      <td>Go back in time - Watch this movie: This is a ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                      text  label\n","3265217  JUNK / Bad Seller!!: I paid $7.63 for this ite...      1\n","3207238  An awesome book by a wonderful author: I met L...      2\n","1359854  Too small and awkward: While cute, this little...      1\n","1715468  Very enjoyable: Feels like I've spent a month ...      2\n","2670191  Go back in time - Watch this movie: This is a ...      2"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"zUTpz7RZF1H1","colab_type":"code","colab":{}},"source":["#Clean text\n","\n","stop = stopwords.words('english')\n","w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n","lemmatizer = nltk.stem.WordNetLemmatizer()\n","\n","def lemmatize_text(text):\n","    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n","\n","#lowercase and remove punctuation, remove stopwords        \n","df['text'] = df['text'].str.lower()\n","df['text'] = df['text'].str.replace('-', ' ')\n","df['text'] = df['text'].str.split(' ')\n","df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n","df['text'] = df['text'].apply(', '.join)\n","df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n","df['text'] = df['text'].apply(lemmatize_text)\n","df['text'] = df['text'].apply(', '.join)\n","df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n","df['text'] = df['text'].str.replace('\\\\', ' ')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v716GFtjF1H4","colab_type":"code","colab":{}},"source":["#Train Word2Vec\n","\n","from gensim.models import Word2Vec\n","\n","text = [row.split() for row in df['text']]\n","model_w2v = Word2Vec(text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeO9W1afF1H6","colab_type":"code","colab":{}},"source":["model_w2v.save('model_w2v.bin')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"okwCWi8WF1H8","colab_type":"code","outputId":"9de3534a-ed71-436e-8977-6e81c611e796","colab":{}},"source":["#Average Word2Vec Vectors for BOW\n","\n","from tqdm import tqdm\n","\n","text_vec = []\n","text_avg_vec = []\n","count = 0\n","for row in tqdm(range(len(text))):\n","    [word.split(' ', 1) for word in text[row]]\n","  \n","    for i in range(len(text[row])):\n","        try:\n","            text_vec.append(model_w2v[text[row][i]])\n","            count = count + 1\n","        except KeyError as e:\n","            text_vec.append([0]*100)\n","  \n","    average = np.add.reduce(text_vec)\n","    if count==0:\n","        count = 1\n","    average = np.divide(average, count)\n","    text_avg_vec.append(average)\n","    text_vec = []\n","    count = 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  0%|          | 0/120000 [00:00<?, ?it/s]/home/danielamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  # This is added back by InteractiveShellApp.init_path()\n","100%|██████████| 120000/120000 [00:20<00:00, 5788.63it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"TEdesJclF1H_","colab_type":"code","colab":{}},"source":["for i in range(len(text_avg_vec)):\n","    if type(text_avg_vec[i]) != np.ndarray:\n","        text_avg_vec[i] = np.zeros(100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LEbtDl_-F1IC","colab_type":"code","colab":{}},"source":["x_train = text_avg_vec\n","x_train = np.c_[x_train]\n","\n","df['label'] = df['label'] - 1\n","\n","y_train= np.asarray(df.label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYOMPOgOF1IE","colab_type":"code","outputId":"8d45e2c8-90f8-4889-827f-fb462dd3b2ab","colab":{}},"source":["#Logistic Regression Training\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression().fit(x_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/danielamin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6fJCW9CRF1IH","colab_type":"code","colab":{}},"source":["#Naive Bayes Training\n","\n","from sklearn.naive_bayes import GaussianNB\n","clf = GaussianNB().fit(x_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3i2eWSaLF1IJ","colab_type":"code","outputId":"291db352-78e8-4a8b-f9ae-a6fceb9d7601","colab":{}},"source":["#Deep Neural net Training\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential, load_model\n","\n","# mini batches Nadam optimizer with dropout and batch normalization\n","epochs = 100\n","model = tf.keras.Sequential()\n","model.add(layers.Dense(32, input_dim=100))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(32))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.2))\n","model.add(layers.Dense(32))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(64))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.3))\n","model.add(layers.Dense(64))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(64))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.4))\n","\n","model.add(layers.Dense(1))\n","model.add(layers.Activation('sigmoid'))\n","model.compile(loss='binary_crossentropy',\n","              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n","              metrics=['accuracy'])\n","checkpoint = keras.callbacks.ModelCheckpoint(\"NN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n","\n","model.summary()\n","model1 = model.fit(x_train, y_train, epochs=epochs, validation_split=0.2, callbacks=[checkpoint])\n","#history = model.fit(x_train, y_train, epochs = epochs, validation_split=0.2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_14 (Dense)             (None, 32)                3232      \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 64)                2112      \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 64)                4160      \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 64)                4160      \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 1)                 65        \n","_________________________________________________________________\n","activation_20 (Activation)   (None, 1)                 0         \n","=================================================================\n","Total params: 16,993\n","Trainable params: 16,417\n","Non-trainable params: 576\n","_________________________________________________________________\n","Train on 96000 samples, validate on 24000 samples\n","Epoch 1/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8113\n","Epoch 00001: val_accuracy improved from -inf to 0.84704, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 22s 234us/sample - loss: 0.4179 - accuracy: 0.8113 - val_loss: 0.3487 - val_accuracy: 0.8470\n","Epoch 2/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8367\n","Epoch 00002: val_accuracy improved from 0.84704 to 0.85250, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 19s 200us/sample - loss: 0.3711 - accuracy: 0.8367 - val_loss: 0.3367 - val_accuracy: 0.8525\n","Epoch 3/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.8386\n","Epoch 00003: val_accuracy did not improve from 0.85250\n","96000/96000 [==============================] - 17s 181us/sample - loss: 0.3658 - accuracy: 0.8387 - val_loss: 0.3490 - val_accuracy: 0.8465\n","Epoch 4/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.8422\n","Epoch 00004: val_accuracy improved from 0.85250 to 0.85404, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 20s 210us/sample - loss: 0.3610 - accuracy: 0.8422 - val_loss: 0.3390 - val_accuracy: 0.8540\n","Epoch 5/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.8435\n","Epoch 00005: val_accuracy did not improve from 0.85404\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3565 - accuracy: 0.8435 - val_loss: 0.3439 - val_accuracy: 0.8518\n","Epoch 6/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.8434\n","Epoch 00006: val_accuracy did not improve from 0.85404\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3557 - accuracy: 0.8434 - val_loss: 0.3387 - val_accuracy: 0.8507\n","Epoch 7/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8455\n","Epoch 00007: val_accuracy improved from 0.85404 to 0.85425, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 19s 198us/sample - loss: 0.3524 - accuracy: 0.8455 - val_loss: 0.3297 - val_accuracy: 0.8543\n","Epoch 8/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8475\n","Epoch 00008: val_accuracy improved from 0.85425 to 0.85617, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 19s 203us/sample - loss: 0.3514 - accuracy: 0.8475 - val_loss: 0.3311 - val_accuracy: 0.8562\n","Epoch 9/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8476\n","Epoch 00009: val_accuracy improved from 0.85617 to 0.85779, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 20s 207us/sample - loss: 0.3495 - accuracy: 0.8476 - val_loss: 0.3283 - val_accuracy: 0.8578\n","Epoch 10/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.8504\n","Epoch 00010: val_accuracy did not improve from 0.85779\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3464 - accuracy: 0.8504 - val_loss: 0.3281 - val_accuracy: 0.8574\n","Epoch 11/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8507\n","Epoch 00011: val_accuracy did not improve from 0.85779\n","96000/96000 [==============================] - 17s 181us/sample - loss: 0.3456 - accuracy: 0.8506 - val_loss: 0.3337 - val_accuracy: 0.8545\n","Epoch 12/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8502\n","Epoch 00012: val_accuracy improved from 0.85779 to 0.86042, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 20s 207us/sample - loss: 0.3458 - accuracy: 0.8501 - val_loss: 0.3271 - val_accuracy: 0.8604\n","Epoch 13/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8514\n","Epoch 00013: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 179us/sample - loss: 0.3428 - accuracy: 0.8513 - val_loss: 0.3277 - val_accuracy: 0.8589\n","Epoch 14/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8526\n","Epoch 00014: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 182us/sample - loss: 0.3428 - accuracy: 0.8526 - val_loss: 0.3280 - val_accuracy: 0.8577\n","Epoch 15/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.8539\n","Epoch 00015: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3394 - accuracy: 0.8538 - val_loss: 0.3305 - val_accuracy: 0.8585\n","Epoch 16/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8539\n","Epoch 00016: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 182us/sample - loss: 0.3407 - accuracy: 0.8539 - val_loss: 0.3253 - val_accuracy: 0.8585\n","Epoch 17/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3395 - accuracy: 0.8547\n","Epoch 00017: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 177us/sample - loss: 0.3395 - accuracy: 0.8547 - val_loss: 0.3268 - val_accuracy: 0.8576\n","Epoch 18/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.8549\n","Epoch 00018: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 179us/sample - loss: 0.3386 - accuracy: 0.8548 - val_loss: 0.3267 - val_accuracy: 0.8598\n","Epoch 19/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.8552\n","Epoch 00019: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3370 - accuracy: 0.8552 - val_loss: 0.3299 - val_accuracy: 0.8584\n","Epoch 20/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8559\n","Epoch 00020: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3355 - accuracy: 0.8559 - val_loss: 0.3279 - val_accuracy: 0.8577\n","Epoch 21/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8563\n","Epoch 00021: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 177us/sample - loss: 0.3351 - accuracy: 0.8563 - val_loss: 0.3285 - val_accuracy: 0.8583\n","Epoch 22/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.8561\n","Epoch 00022: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 180us/sample - loss: 0.3358 - accuracy: 0.8560 - val_loss: 0.3255 - val_accuracy: 0.8604\n","Epoch 23/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8577\n","Epoch 00023: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3337 - accuracy: 0.8577 - val_loss: 0.3294 - val_accuracy: 0.8569\n","Epoch 24/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3350 - accuracy: 0.8569\n","Epoch 00024: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 16s 172us/sample - loss: 0.3350 - accuracy: 0.8569 - val_loss: 0.3250 - val_accuracy: 0.8595\n","Epoch 25/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8584\n","Epoch 00025: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3327 - accuracy: 0.8584 - val_loss: 0.3266 - val_accuracy: 0.8592\n","Epoch 26/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8581\n","Epoch 00026: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 18s 183us/sample - loss: 0.3338 - accuracy: 0.8580 - val_loss: 0.3296 - val_accuracy: 0.8584\n","Epoch 27/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.8566\n","Epoch 00027: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3325 - accuracy: 0.8567 - val_loss: 0.3314 - val_accuracy: 0.8571\n","Epoch 28/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.8582\n","Epoch 00028: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 18s 183us/sample - loss: 0.3321 - accuracy: 0.8582 - val_loss: 0.3268 - val_accuracy: 0.8546\n","Epoch 29/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8596\n","Epoch 00029: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 180us/sample - loss: 0.3305 - accuracy: 0.8595 - val_loss: 0.3328 - val_accuracy: 0.8594\n","Epoch 30/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.8590\n","Epoch 00030: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3303 - accuracy: 0.8591 - val_loss: 0.3253 - val_accuracy: 0.8595\n","Epoch 31/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8598\n","Epoch 00031: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3287 - accuracy: 0.8597 - val_loss: 0.3307 - val_accuracy: 0.8601\n","Epoch 32/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.8593\n","Epoch 00032: val_accuracy did not improve from 0.86042\n","96000/96000 [==============================] - 18s 184us/sample - loss: 0.3302 - accuracy: 0.8593 - val_loss: 0.3285 - val_accuracy: 0.8575\n","Epoch 33/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8599\n","Epoch 00033: val_accuracy improved from 0.86042 to 0.86054, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 19s 201us/sample - loss: 0.3295 - accuracy: 0.8599 - val_loss: 0.3254 - val_accuracy: 0.8605\n","Epoch 34/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.3284 - accuracy: 0.8597\n","Epoch 00034: val_accuracy improved from 0.86054 to 0.86058, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 20s 205us/sample - loss: 0.3285 - accuracy: 0.8597 - val_loss: 0.3265 - val_accuracy: 0.8606\n","Epoch 35/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8576\n","Epoch 00035: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3325 - accuracy: 0.8576 - val_loss: 0.3347 - val_accuracy: 0.8593\n","Epoch 36/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8582\n","Epoch 00036: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3308 - accuracy: 0.8581 - val_loss: 0.3264 - val_accuracy: 0.8587\n","Epoch 37/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.8606\n","Epoch 00037: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3276 - accuracy: 0.8606 - val_loss: 0.3274 - val_accuracy: 0.8596\n","Epoch 38/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3295 - accuracy: 0.8595\n","Epoch 00038: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 179us/sample - loss: 0.3294 - accuracy: 0.8595 - val_loss: 0.3250 - val_accuracy: 0.8590\n","Epoch 39/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8576\n","Epoch 00039: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3305 - accuracy: 0.8576 - val_loss: 0.3293 - val_accuracy: 0.8548\n","Epoch 40/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8581\n","Epoch 00040: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3309 - accuracy: 0.8581 - val_loss: 1.5805 - val_accuracy: 0.8589\n","Epoch 41/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.8592\n","Epoch 00041: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3303 - accuracy: 0.8592 - val_loss: 0.3269 - val_accuracy: 0.8574\n","Epoch 42/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8605\n","Epoch 00042: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3293 - accuracy: 0.8604 - val_loss: 0.3528 - val_accuracy: 0.8460\n","Epoch 43/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.8595\n","Epoch 00043: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3297 - accuracy: 0.8594 - val_loss: 0.7732 - val_accuracy: 0.8593\n","Epoch 44/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.8605\n","Epoch 00044: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3287 - accuracy: 0.8604 - val_loss: 0.3286 - val_accuracy: 0.8596\n","Epoch 45/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8602\n","Epoch 00045: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3277 - accuracy: 0.8603 - val_loss: 0.3447 - val_accuracy: 0.8531\n","Epoch 46/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8603\n","Epoch 00046: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3261 - accuracy: 0.8603 - val_loss: 0.3323 - val_accuracy: 0.8601\n","Epoch 47/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8604\n","Epoch 00047: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3263 - accuracy: 0.8605 - val_loss: 0.3241 - val_accuracy: 0.8596\n","Epoch 48/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8608\n","Epoch 00048: val_accuracy did not improve from 0.86058\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3262 - accuracy: 0.8608 - val_loss: 0.3294 - val_accuracy: 0.8594\n","Epoch 49/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8623\n","Epoch 00049: val_accuracy improved from 0.86058 to 0.86063, saving model to NN.model\n","INFO:tensorflow:Assets written to: NN.model/assets\n","96000/96000 [==============================] - 19s 196us/sample - loss: 0.3248 - accuracy: 0.8622 - val_loss: 0.3766 - val_accuracy: 0.8606\n","Epoch 50/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8612\n","Epoch 00050: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 171us/sample - loss: 0.3267 - accuracy: 0.8612 - val_loss: 0.4556 - val_accuracy: 0.8543\n","Epoch 51/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8607\n","Epoch 00051: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3278 - accuracy: 0.8608 - val_loss: 0.3279 - val_accuracy: 0.8578\n","Epoch 52/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8625\n","Epoch 00052: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3262 - accuracy: 0.8624 - val_loss: 0.3251 - val_accuracy: 0.8581\n","Epoch 53/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8602\n","Epoch 00053: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3262 - accuracy: 0.8603 - val_loss: 1.6039 - val_accuracy: 0.8578\n","Epoch 54/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8615\n","Epoch 00054: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3231 - accuracy: 0.8616 - val_loss: 0.3319 - val_accuracy: 0.8569\n","Epoch 55/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8617\n","Epoch 00055: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3268 - accuracy: 0.8617 - val_loss: 0.3957 - val_accuracy: 0.8575\n","Epoch 56/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8614\n","Epoch 00056: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 177us/sample - loss: 0.3255 - accuracy: 0.8614 - val_loss: 0.4153 - val_accuracy: 0.8603\n","Epoch 57/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8624\n","Epoch 00057: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3235 - accuracy: 0.8624 - val_loss: 0.3261 - val_accuracy: 0.8605\n","Epoch 58/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.8619\n","Epoch 00058: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3228 - accuracy: 0.8619 - val_loss: 0.5037 - val_accuracy: 0.8606\n","Epoch 59/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8624\n","Epoch 00059: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 172us/sample - loss: 0.3248 - accuracy: 0.8622 - val_loss: 0.3324 - val_accuracy: 0.8585\n","Epoch 60/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8632\n","Epoch 00060: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3231 - accuracy: 0.8631 - val_loss: 0.3553 - val_accuracy: 0.8580\n","Epoch 61/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8621\n","Epoch 00061: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3236 - accuracy: 0.8621 - val_loss: 0.9798 - val_accuracy: 0.8547\n","Epoch 62/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8617\n","Epoch 00062: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3251 - accuracy: 0.8617 - val_loss: 0.4018 - val_accuracy: 0.8588\n","Epoch 63/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8624\n","Epoch 00063: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3237 - accuracy: 0.8624 - val_loss: 0.3311 - val_accuracy: 0.8583\n","Epoch 64/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8616\n","Epoch 00064: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3248 - accuracy: 0.8616 - val_loss: 0.3301 - val_accuracy: 0.8562\n","Epoch 65/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8629\n","Epoch 00065: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 177us/sample - loss: 0.3237 - accuracy: 0.8628 - val_loss: 0.3284 - val_accuracy: 0.8572\n","Epoch 66/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8619\n","Epoch 00066: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3233 - accuracy: 0.8618 - val_loss: 0.3400 - val_accuracy: 0.8573\n","Epoch 67/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8639\n","Epoch 00067: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3218 - accuracy: 0.8639 - val_loss: 0.3272 - val_accuracy: 0.8584\n","Epoch 68/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8609\n","Epoch 00068: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3254 - accuracy: 0.8610 - val_loss: 0.3297 - val_accuracy: 0.8583\n","Epoch 69/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.8632\n","Epoch 00069: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3213 - accuracy: 0.8632 - val_loss: 0.3411 - val_accuracy: 0.8473\n","Epoch 70/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8618\n","Epoch 00070: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3230 - accuracy: 0.8618 - val_loss: 0.3246 - val_accuracy: 0.8587\n","Epoch 71/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.8614\n","Epoch 00071: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3260 - accuracy: 0.8615 - val_loss: 0.3342 - val_accuracy: 0.8589\n","Epoch 72/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8626\n","Epoch 00072: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 172us/sample - loss: 0.3237 - accuracy: 0.8625 - val_loss: 0.3993 - val_accuracy: 0.8587\n","Epoch 73/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8626\n","Epoch 00073: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3231 - accuracy: 0.8626 - val_loss: 0.3259 - val_accuracy: 0.8589\n","Epoch 74/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.8625\n","Epoch 00074: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3225 - accuracy: 0.8625 - val_loss: 0.5345 - val_accuracy: 0.8588\n","Epoch 75/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.8633\n","Epoch 00075: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3227 - accuracy: 0.8634 - val_loss: 0.3862 - val_accuracy: 0.8588\n","Epoch 76/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8631\n","Epoch 00076: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3209 - accuracy: 0.8632 - val_loss: 2.1161 - val_accuracy: 0.8595\n","Epoch 77/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.8635\n","Epoch 00077: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 176us/sample - loss: 0.3218 - accuracy: 0.8634 - val_loss: 0.3355 - val_accuracy: 0.8583\n","Epoch 78/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.8631\n","Epoch 00078: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3223 - accuracy: 0.8632 - val_loss: 0.3324 - val_accuracy: 0.8595\n","Epoch 79/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3211 - accuracy: 0.8632\n","Epoch 00079: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.3211 - accuracy: 0.8632 - val_loss: 0.3464 - val_accuracy: 0.8584\n","Epoch 80/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8639\n","Epoch 00080: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3210 - accuracy: 0.8639 - val_loss: 0.3425 - val_accuracy: 0.8597\n","Epoch 81/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8637\n","Epoch 00081: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 172us/sample - loss: 0.3209 - accuracy: 0.8637 - val_loss: 0.3273 - val_accuracy: 0.8598\n","Epoch 82/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8641\n","Epoch 00082: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3197 - accuracy: 0.8641 - val_loss: 0.3298 - val_accuracy: 0.8561\n","Epoch 83/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8643\n","Epoch 00083: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3198 - accuracy: 0.8643 - val_loss: 1.9804 - val_accuracy: 0.8576\n","Epoch 84/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.8637\n","Epoch 00084: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3200 - accuracy: 0.8637 - val_loss: 0.3293 - val_accuracy: 0.8586\n","Epoch 85/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8628\n","Epoch 00085: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 170us/sample - loss: 0.3205 - accuracy: 0.8628 - val_loss: 1.2762 - val_accuracy: 0.8590\n","Epoch 86/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.8656\n","Epoch 00086: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3176 - accuracy: 0.8655 - val_loss: 4.7551 - val_accuracy: 0.8592\n","Epoch 87/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.8638\n","Epoch 00087: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 171us/sample - loss: 0.3205 - accuracy: 0.8638 - val_loss: 0.6558 - val_accuracy: 0.8574\n","Epoch 88/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.8642\n","Epoch 00088: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 16s 172us/sample - loss: 0.3186 - accuracy: 0.8642 - val_loss: 0.3336 - val_accuracy: 0.8578\n","Epoch 89/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.8642\n","Epoch 00089: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3194 - accuracy: 0.8642 - val_loss: 0.3333 - val_accuracy: 0.8569\n","Epoch 90/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3205 - accuracy: 0.8628\n","Epoch 00090: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3204 - accuracy: 0.8628 - val_loss: 0.3262 - val_accuracy: 0.8597\n","Epoch 91/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8631\n","Epoch 00091: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3205 - accuracy: 0.8631 - val_loss: 0.4272 - val_accuracy: 0.8568\n","Epoch 92/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3212 - accuracy: 0.8630\n","Epoch 00092: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 18s 185us/sample - loss: 0.3211 - accuracy: 0.8630 - val_loss: 0.3521 - val_accuracy: 0.8600\n","Epoch 93/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.8629\n","Epoch 00093: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 19s 200us/sample - loss: 0.3221 - accuracy: 0.8629 - val_loss: 0.3278 - val_accuracy: 0.8584\n","Epoch 94/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8646\n","Epoch 00094: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 180us/sample - loss: 0.3182 - accuracy: 0.8647 - val_loss: 0.3309 - val_accuracy: 0.8595\n","Epoch 95/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8644\n","Epoch 00095: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 18s 182us/sample - loss: 0.3183 - accuracy: 0.8644 - val_loss: 2.6574 - val_accuracy: 0.8589\n","Epoch 96/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.8657\n","Epoch 00096: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 18s 188us/sample - loss: 0.3176 - accuracy: 0.8657 - val_loss: 0.3273 - val_accuracy: 0.8592\n","Epoch 97/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.8632\n","Epoch 00097: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 18s 184us/sample - loss: 0.3196 - accuracy: 0.8631 - val_loss: 0.3307 - val_accuracy: 0.8583\n","Epoch 98/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8646\n","Epoch 00098: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 177us/sample - loss: 0.3184 - accuracy: 0.8646 - val_loss: 2.2439 - val_accuracy: 0.8604\n","Epoch 99/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8649\n","Epoch 00099: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 18s 184us/sample - loss: 0.3179 - accuracy: 0.8649 - val_loss: 0.6588 - val_accuracy: 0.8586\n","Epoch 100/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3202 - accuracy: 0.8637\n","Epoch 00100: val_accuracy did not improve from 0.86063\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3202 - accuracy: 0.8637 - val_loss: 0.5610 - val_accuracy: 0.8595\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mk1DENr1F1IM","colab_type":"code","outputId":"400fe73d-38e3-440a-c119-54e9a7f673cd","colab":{}},"source":["x_train1 = x_train.reshape(120000, x_train.shape[1], 1)\n","print(x_train1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(120000, 100, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LksvhGHzF1IO","colab_type":"code","colab":{}},"source":["#CNN Training\n","\n","import tensorflow as tf\n","\n","shape = (x_train.shape[1], 1)\n","model = tf.keras.models.Sequential()\n","\n","model.add(tf.keras.layers.Conv1D(32, kernel_size=3, activation=tf.nn.relu, input_shape=shape))\n","model.add(tf.keras.layers.Conv1D(32, kernel_size=3, activation=tf.nn.relu))\n","\n","model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","          \n","model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation=tf.nn.relu))\n","          \n","model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","          \n","model.add(tf.keras.layers.Conv1D(128, kernel_size=3, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Conv1D(128, kernel_size=3, activation=tf.nn.relu))\n","          \n","model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n","          \n","model.add(tf.keras.layers.Conv1D(256, kernel_size=3, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Conv1D(256, kernel_size=3, activation=tf.nn.relu))\n","          \n","model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.BatchNormalization())\n","          \n","model.add(tf.keras.layers.Dense(200, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n","\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZsmP3VAF1IQ","colab_type":"code","outputId":"4be1564e-b6bc-483f-c0b9-876dde82b12b","colab":{}},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(\"CNN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n","model2 = model.fit(x_train1, y_train, epochs=100, validation_split=0.2, callbacks=[checkpoint])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 96000 samples, validate on 24000 samples\n","Epoch 1/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.4179 - accuracy: 0.8086\n","Epoch 00001: val_accuracy improved from -inf to 0.83017, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 19s 201us/sample - loss: 0.4180 - accuracy: 0.8086 - val_loss: 0.3828 - val_accuracy: 0.8302\n","Epoch 2/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8310\n","Epoch 00002: val_accuracy did not improve from 0.83017\n","96000/96000 [==============================] - 17s 179us/sample - loss: 0.3788 - accuracy: 0.8311 - val_loss: 0.4988 - val_accuracy: 0.7315\n","Epoch 3/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.8375\n","Epoch 00003: val_accuracy improved from 0.83017 to 0.84704, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 18s 186us/sample - loss: 0.3661 - accuracy: 0.8376 - val_loss: 0.3748 - val_accuracy: 0.8470\n","Epoch 4/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.8430\n","Epoch 00004: val_accuracy did not improve from 0.84704\n","96000/96000 [==============================] - 16s 169us/sample - loss: 0.3567 - accuracy: 0.8430 - val_loss: 0.3489 - val_accuracy: 0.8432\n","Epoch 5/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8442\n","Epoch 00005: val_accuracy did not improve from 0.84704\n","96000/96000 [==============================] - 17s 178us/sample - loss: 0.3510 - accuracy: 0.8442 - val_loss: 0.4477 - val_accuracy: 0.7830\n","Epoch 6/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8472\n","Epoch 00006: val_accuracy did not improve from 0.84704\n","96000/96000 [==============================] - 16s 166us/sample - loss: 0.3475 - accuracy: 0.8471 - val_loss: 0.3644 - val_accuracy: 0.8428\n","Epoch 7/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8496\n","Epoch 00007: val_accuracy improved from 0.84704 to 0.84800, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 16s 169us/sample - loss: 0.3420 - accuracy: 0.8496 - val_loss: 0.3433 - val_accuracy: 0.8480\n","Epoch 8/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8511\n","Epoch 00008: val_accuracy improved from 0.84800 to 0.84808, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 18s 185us/sample - loss: 0.3390 - accuracy: 0.8511 - val_loss: 0.3443 - val_accuracy: 0.8481\n","Epoch 9/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8540\n","Epoch 00009: val_accuracy did not improve from 0.84808\n","96000/96000 [==============================] - 16s 168us/sample - loss: 0.3345 - accuracy: 0.8540 - val_loss: 0.3547 - val_accuracy: 0.8426\n","Epoch 10/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.8506\n","Epoch 00010: val_accuracy did not improve from 0.84808\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.3416 - accuracy: 0.8505 - val_loss: 0.4350 - val_accuracy: 0.8138\n","Epoch 11/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.3336 - accuracy: 0.8531\n","Epoch 00011: val_accuracy improved from 0.84808 to 0.85071, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 16s 170us/sample - loss: 0.3336 - accuracy: 0.8531 - val_loss: 0.3367 - val_accuracy: 0.8507\n","Epoch 12/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8561\n","Epoch 00012: val_accuracy did not improve from 0.85071\n","96000/96000 [==============================] - 16s 169us/sample - loss: 0.3289 - accuracy: 0.8561 - val_loss: 0.3924 - val_accuracy: 0.8449\n","Epoch 13/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8580\n","Epoch 00013: val_accuracy did not improve from 0.85071\n","96000/96000 [==============================] - 16s 170us/sample - loss: 0.3258 - accuracy: 0.8580 - val_loss: 0.3425 - val_accuracy: 0.8488\n","Epoch 14/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8592\n","Epoch 00014: val_accuracy did not improve from 0.85071\n","96000/96000 [==============================] - 15s 161us/sample - loss: 0.3241 - accuracy: 0.8592 - val_loss: 0.3445 - val_accuracy: 0.8465\n","Epoch 15/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8602\n","Epoch 00015: val_accuracy improved from 0.85071 to 0.85362, saving model to CNN.model\n","INFO:tensorflow:Assets written to: CNN.model/assets\n","96000/96000 [==============================] - 17s 174us/sample - loss: 0.3208 - accuracy: 0.8602 - val_loss: 0.3372 - val_accuracy: 0.8536\n","Epoch 16/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8626\n","Epoch 00016: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 162us/sample - loss: 0.3179 - accuracy: 0.8626 - val_loss: 0.3440 - val_accuracy: 0.8490\n","Epoch 17/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8618\n","Epoch 00017: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 166us/sample - loss: 0.3159 - accuracy: 0.8617 - val_loss: 0.3430 - val_accuracy: 0.8471\n","Epoch 18/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.8639\n","Epoch 00018: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 17s 173us/sample - loss: 0.3123 - accuracy: 0.8640 - val_loss: 0.3887 - val_accuracy: 0.8316\n","Epoch 19/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.8637\n","Epoch 00019: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 160us/sample - loss: 0.3103 - accuracy: 0.8637 - val_loss: 0.3445 - val_accuracy: 0.8489\n","Epoch 20/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8673\n","Epoch 00020: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 159us/sample - loss: 0.3082 - accuracy: 0.8673 - val_loss: 0.3420 - val_accuracy: 0.8515\n","Epoch 21/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8684\n","Epoch 00021: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 17s 175us/sample - loss: 0.3044 - accuracy: 0.8684 - val_loss: 0.3594 - val_accuracy: 0.8493\n","Epoch 22/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8682\n","Epoch 00022: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 169us/sample - loss: 0.3027 - accuracy: 0.8683 - val_loss: 0.3493 - val_accuracy: 0.8509\n","Epoch 23/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8702\n","Epoch 00023: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 164us/sample - loss: 0.3005 - accuracy: 0.8701 - val_loss: 0.3554 - val_accuracy: 0.8456\n","Epoch 24/100\n","95584/96000 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.8712\n","Epoch 00024: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 162us/sample - loss: 0.2972 - accuracy: 0.8712 - val_loss: 0.3451 - val_accuracy: 0.8496\n","Epoch 25/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.8719\n","Epoch 00025: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.2939 - accuracy: 0.8719 - val_loss: 0.3592 - val_accuracy: 0.8447\n","Epoch 26/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8722\n","Epoch 00026: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 160us/sample - loss: 0.2938 - accuracy: 0.8722 - val_loss: 0.3678 - val_accuracy: 0.8384\n","Epoch 27/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8746\n","Epoch 00027: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 160us/sample - loss: 0.2887 - accuracy: 0.8747 - val_loss: 0.3530 - val_accuracy: 0.8498\n","Epoch 28/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8753\n","Epoch 00028: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.2874 - accuracy: 0.8753 - val_loss: 0.3534 - val_accuracy: 0.8475\n","Epoch 29/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.8768\n","Epoch 00029: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 158us/sample - loss: 0.2842 - accuracy: 0.8767 - val_loss: 0.3616 - val_accuracy: 0.8491\n","Epoch 30/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.8776\n","Epoch 00030: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.2814 - accuracy: 0.8776 - val_loss: 0.3518 - val_accuracy: 0.8495\n","Epoch 31/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.8795\n","Epoch 00031: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.2778 - accuracy: 0.8794 - val_loss: 0.3604 - val_accuracy: 0.8461\n","Epoch 32/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.8806\n","Epoch 00032: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 163us/sample - loss: 0.2764 - accuracy: 0.8806 - val_loss: 0.3666 - val_accuracy: 0.8463\n","Epoch 33/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8818\n","Epoch 00033: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 162us/sample - loss: 0.2736 - accuracy: 0.8818 - val_loss: 0.3764 - val_accuracy: 0.8449\n","Epoch 34/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.8834\n","Epoch 00034: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.2708 - accuracy: 0.8834 - val_loss: 0.3706 - val_accuracy: 0.8417\n","Epoch 35/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.8837\n","Epoch 00035: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.2683 - accuracy: 0.8837 - val_loss: 0.3733 - val_accuracy: 0.8428\n","Epoch 36/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.8843\n","Epoch 00036: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 164us/sample - loss: 0.2662 - accuracy: 0.8842 - val_loss: 0.3945 - val_accuracy: 0.8436\n","Epoch 37/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.8851\n","Epoch 00037: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 168us/sample - loss: 0.2640 - accuracy: 0.8850 - val_loss: 0.3906 - val_accuracy: 0.8385\n","Epoch 38/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2614 - accuracy: 0.8868\n","Epoch 00038: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 159us/sample - loss: 0.2614 - accuracy: 0.8869 - val_loss: 0.3779 - val_accuracy: 0.8417\n","Epoch 39/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.8883\n","Epoch 00039: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 161us/sample - loss: 0.2574 - accuracy: 0.8882 - val_loss: 0.4085 - val_accuracy: 0.8406\n","Epoch 40/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.8897\n","Epoch 00040: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 162us/sample - loss: 0.2559 - accuracy: 0.8897 - val_loss: 0.4031 - val_accuracy: 0.8420\n","Epoch 41/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.8898\n","Epoch 00041: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 158us/sample - loss: 0.2541 - accuracy: 0.8898 - val_loss: 0.3894 - val_accuracy: 0.8450\n","Epoch 42/100\n","95616/96000 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.8919\n","Epoch 00042: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.2505 - accuracy: 0.8919 - val_loss: 0.3951 - val_accuracy: 0.8362\n","Epoch 43/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.2486 - accuracy: 0.8916\n","Epoch 00043: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.2486 - accuracy: 0.8916 - val_loss: 0.4142 - val_accuracy: 0.8434\n","Epoch 44/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.8925\n","Epoch 00044: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 152us/sample - loss: 0.2462 - accuracy: 0.8925 - val_loss: 0.4177 - val_accuracy: 0.8430\n","Epoch 45/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2437 - accuracy: 0.8946\n","Epoch 00045: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 160us/sample - loss: 0.2436 - accuracy: 0.8946 - val_loss: 0.4134 - val_accuracy: 0.8398\n","Epoch 46/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.8950\n","Epoch 00046: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.2414 - accuracy: 0.8950 - val_loss: 0.4254 - val_accuracy: 0.8419\n","Epoch 47/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.2395 - accuracy: 0.8954\n","Epoch 00047: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.2396 - accuracy: 0.8954 - val_loss: 0.4281 - val_accuracy: 0.8414\n","Epoch 48/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.8979\n","Epoch 00048: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 164us/sample - loss: 0.2360 - accuracy: 0.8978 - val_loss: 0.4375 - val_accuracy: 0.8322\n","Epoch 49/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.8982\n","Epoch 00049: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 163us/sample - loss: 0.2340 - accuracy: 0.8982 - val_loss: 0.4324 - val_accuracy: 0.8372\n","Epoch 50/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.8986\n","Epoch 00050: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 161us/sample - loss: 0.2319 - accuracy: 0.8987 - val_loss: 0.4272 - val_accuracy: 0.8390\n","Epoch 51/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.2308 - accuracy: 0.8995\n","Epoch 00051: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.2308 - accuracy: 0.8995 - val_loss: 0.4270 - val_accuracy: 0.8384\n","Epoch 52/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9002\n","Epoch 00052: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.2288 - accuracy: 0.9001 - val_loss: 0.4932 - val_accuracy: 0.8332\n","Epoch 53/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9017\n","Epoch 00053: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 150us/sample - loss: 0.2264 - accuracy: 0.9017 - val_loss: 0.4477 - val_accuracy: 0.8429\n","Epoch 54/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.2245 - accuracy: 0.9029\n","Epoch 00054: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.2244 - accuracy: 0.9030 - val_loss: 0.4230 - val_accuracy: 0.8370\n","Epoch 55/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9038\n","Epoch 00055: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.2215 - accuracy: 0.9038 - val_loss: 0.5340 - val_accuracy: 0.8271\n","Epoch 56/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9051\n","Epoch 00056: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 159us/sample - loss: 0.2201 - accuracy: 0.9051 - val_loss: 0.4992 - val_accuracy: 0.8387\n","Epoch 57/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9068\n","Epoch 00057: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 151us/sample - loss: 0.2160 - accuracy: 0.9068 - val_loss: 0.4579 - val_accuracy: 0.8380\n","Epoch 58/100\n","95584/96000 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9067\n","Epoch 00058: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.2153 - accuracy: 0.9066 - val_loss: 0.4742 - val_accuracy: 0.8321\n","Epoch 59/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9074\n","Epoch 00059: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.2127 - accuracy: 0.9074 - val_loss: 0.5148 - val_accuracy: 0.8314\n","Epoch 60/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9090\n","Epoch 00060: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.2125 - accuracy: 0.9091 - val_loss: 0.4736 - val_accuracy: 0.8365\n","Epoch 61/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9090\n","Epoch 00061: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 150us/sample - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.4817 - val_accuracy: 0.8370\n","Epoch 62/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9105\n","Epoch 00062: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.2079 - accuracy: 0.9105 - val_loss: 0.4906 - val_accuracy: 0.8355\n","Epoch 63/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 0.9103\n","Epoch 00063: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.2071 - accuracy: 0.9103 - val_loss: 0.4858 - val_accuracy: 0.8334\n","Epoch 64/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9119\n","Epoch 00064: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.2021 - accuracy: 0.9120 - val_loss: 0.4885 - val_accuracy: 0.8291\n","Epoch 65/100\n","95808/96000 [============================>.] - ETA: 0s - loss: 0.2041 - accuracy: 0.9118\n","Epoch 00065: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.4918 - val_accuracy: 0.8398\n","Epoch 66/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9143\n","Epoch 00066: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.1995 - accuracy: 0.9143 - val_loss: 0.4937 - val_accuracy: 0.8255\n","Epoch 67/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.1985 - accuracy: 0.9140\n","Epoch 00067: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 151us/sample - loss: 0.1985 - accuracy: 0.9140 - val_loss: 0.5528 - val_accuracy: 0.8378\n","Epoch 68/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9148\n","Epoch 00068: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 148us/sample - loss: 0.1955 - accuracy: 0.9149 - val_loss: 0.4973 - val_accuracy: 0.8317\n","Epoch 69/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9154\n","Epoch 00069: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.1950 - accuracy: 0.9154 - val_loss: 0.5137 - val_accuracy: 0.8270\n","Epoch 70/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9165\n","Epoch 00070: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.1928 - accuracy: 0.9166 - val_loss: 0.5159 - val_accuracy: 0.8264\n","Epoch 71/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9170\n","Epoch 00071: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.1922 - accuracy: 0.9170 - val_loss: 0.9014 - val_accuracy: 0.8264\n","Epoch 72/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9173\n","Epoch 00072: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 163us/sample - loss: 0.1915 - accuracy: 0.9172 - val_loss: 0.5106 - val_accuracy: 0.8251\n","Epoch 73/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9188\n","Epoch 00073: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.1886 - accuracy: 0.9188 - val_loss: 0.5354 - val_accuracy: 0.8220\n","Epoch 74/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9190\n","Epoch 00074: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 152us/sample - loss: 0.1880 - accuracy: 0.9189 - val_loss: 0.5211 - val_accuracy: 0.8316\n","Epoch 75/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9194\n","Epoch 00075: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.1858 - accuracy: 0.9195 - val_loss: 0.5368 - val_accuracy: 0.8273\n","Epoch 76/100\n","95616/96000 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9200\n","Epoch 00076: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.1839 - accuracy: 0.9199 - val_loss: 0.5445 - val_accuracy: 0.8294\n","Epoch 77/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9206\n","Epoch 00077: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 17s 172us/sample - loss: 0.1830 - accuracy: 0.9206 - val_loss: 0.5717 - val_accuracy: 0.8326\n","Epoch 78/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9219\n","Epoch 00078: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.1808 - accuracy: 0.9219 - val_loss: 0.5757 - val_accuracy: 0.8341\n","Epoch 79/100\n","95616/96000 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9228\n","Epoch 00079: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 158us/sample - loss: 0.1803 - accuracy: 0.9229 - val_loss: 0.5651 - val_accuracy: 0.8278\n","Epoch 80/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9236\n","Epoch 00080: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 162us/sample - loss: 0.1769 - accuracy: 0.9235 - val_loss: 0.5846 - val_accuracy: 0.8272\n","Epoch 81/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9242\n","Epoch 00081: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.1765 - accuracy: 0.9243 - val_loss: 0.5678 - val_accuracy: 0.8257\n","Epoch 82/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9243\n","Epoch 00082: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 16s 163us/sample - loss: 0.1756 - accuracy: 0.9243 - val_loss: 0.7349 - val_accuracy: 0.8283\n","Epoch 83/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9258\n","Epoch 00083: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 157us/sample - loss: 0.1741 - accuracy: 0.9258 - val_loss: 0.5583 - val_accuracy: 0.8291\n","Epoch 84/100\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9251\n","Epoch 00084: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 149us/sample - loss: 0.1727 - accuracy: 0.9251 - val_loss: 0.5827 - val_accuracy: 0.8191\n","Epoch 85/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9274\n","Epoch 00085: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 161us/sample - loss: 0.1698 - accuracy: 0.9274 - val_loss: 0.5887 - val_accuracy: 0.8274\n","Epoch 86/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9268\n","Epoch 00086: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.1706 - accuracy: 0.9267 - val_loss: 0.5894 - val_accuracy: 0.8322\n","Epoch 87/100\n","95680/96000 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9277\n","Epoch 00087: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 148us/sample - loss: 0.1679 - accuracy: 0.9277 - val_loss: 0.6177 - val_accuracy: 0.8290\n","Epoch 88/100\n","95648/96000 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9282\n","Epoch 00088: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 150us/sample - loss: 0.1664 - accuracy: 0.9282 - val_loss: 0.5839 - val_accuracy: 0.8294\n","Epoch 89/100\n","95872/96000 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9279\n","Epoch 00089: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 153us/sample - loss: 0.1669 - accuracy: 0.9278 - val_loss: 0.9700 - val_accuracy: 0.8105\n","Epoch 90/100\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9292\n","Epoch 00090: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 146us/sample - loss: 0.1647 - accuracy: 0.9292 - val_loss: 0.6576 - val_accuracy: 0.8260\n","Epoch 91/100\n","95616/96000 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9302\n","Epoch 00091: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.1639 - accuracy: 0.9303 - val_loss: 0.5789 - val_accuracy: 0.8250\n","Epoch 92/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9294\n","Epoch 00092: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.1636 - accuracy: 0.9294 - val_loss: 0.5957 - val_accuracy: 0.8295\n","Epoch 93/100\n","95744/96000 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9314\n","Epoch 00093: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 14s 151us/sample - loss: 0.1607 - accuracy: 0.9312 - val_loss: 0.6080 - val_accuracy: 0.8259\n","Epoch 94/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.9320\n","Epoch 00094: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 158us/sample - loss: 0.1599 - accuracy: 0.9320 - val_loss: 1.2811 - val_accuracy: 0.8257\n","Epoch 95/100\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9325\n","Epoch 00095: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 156us/sample - loss: 0.1579 - accuracy: 0.9325 - val_loss: 0.5933 - val_accuracy: 0.8280\n","Epoch 96/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9335\n","Epoch 00096: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.1574 - accuracy: 0.9334 - val_loss: 1.5745 - val_accuracy: 0.8277\n","Epoch 97/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9346\n","Epoch 00097: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 159us/sample - loss: 0.1540 - accuracy: 0.9346 - val_loss: 0.6456 - val_accuracy: 0.8255\n","Epoch 98/100\n","95968/96000 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9341\n","Epoch 00098: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 152us/sample - loss: 0.1569 - accuracy: 0.9340 - val_loss: 0.6258 - val_accuracy: 0.8207\n","Epoch 99/100\n","95712/96000 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9348\n","Epoch 00099: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 154us/sample - loss: 0.1528 - accuracy: 0.9348 - val_loss: 0.6323 - val_accuracy: 0.8241\n","Epoch 100/100\n","95904/96000 [============================>.] - ETA: 0s - loss: 0.1526 - accuracy: 0.9358\n","Epoch 00100: val_accuracy did not improve from 0.85362\n","96000/96000 [==============================] - 15s 155us/sample - loss: 0.1526 - accuracy: 0.9358 - val_loss: 0.6435 - val_accuracy: 0.8268\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rfak2r_3F1IT","colab_type":"code","colab":{}},"source":["#Load and Clean test file\n","\n","text_file = open(\"test1.ft.txt\", \"r\", encoding=\"utf8\")\n","lines = text_file.read().split('\\n')\n","\n","labels = []\n","for item in lines:\n","    first_four_letters = item[:10]\n","    if first_four_letters == '__label__1':\n","        labels.append(int(1))\n","    else:\n","        labels.append(int(2))\n","        \n","def remove_label(s):\n","    return s[11:]\n","lines = [remove_label(s) for s in lines]\n","\n","df = pd.DataFrame()\n","df['text'] = lines\n","df['label'] = labels\n","\n","stop = stopwords.words('english')\n","w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n","lemmatizer = nltk.stem.WordNetLemmatizer()\n","\n","def lemmatize_text(text):\n","    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n","\n","#lowercase and remove punctuation, remove stopwords        \n","df['text'] = df['text'].str.lower()\n","df['text'] = df['text'].str.replace('-', ' ')\n","df['text'] = df['text'].str.split(' ')\n","df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n","df['text'] = df['text'].apply(', '.join)\n","df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n","df['text'] = df['text'].apply(lemmatize_text)\n","df['text'] = df['text'].apply(', '.join)\n","df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n","df['text'] = df['text'].str.replace('\\\\', ' ')\n","\n","df = df.sample(40000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMhYlNcnF1IV","colab_type":"code","outputId":"bdb06eba-7493-4e4f-d0f6-f6ab037e7f76","colab":{}},"source":["#Embed Word2Vec and BOW\n","\n","from tqdm import tqdm\n","\n","text = [row.split() for row in df['text']]\n","text_vec = []\n","text_avg_vec = []\n","count = 0\n","for row in tqdm(range(len(text))):\n","    [word.split(' ', 1) for word in text[row]]\n","  \n","    for i in range(len(text[row])):\n","        try:\n","            text_vec.append(model_w2v[text[row][i]])\n","            count = count + 1\n","        except KeyError as e:\n","            text_vec.append([0]*100)\n","  \n","    average = np.add.reduce(text_vec)\n","    if count==0:\n","        count = 1\n","    average = np.divide(average, count)\n","    text_avg_vec.append(average)\n","    text_vec = []\n","    count = 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  0%|          | 0/40000 [00:00<?, ?it/s]/home/danielamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  if sys.path[0] == '':\n","100%|██████████| 40000/40000 [00:07<00:00, 5480.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"U1tz0Ls2F1IY","colab_type":"code","colab":{}},"source":["for i in range(len(text_avg_vec)):\n","    if type(text_avg_vec[i]) != np.ndarray:\n","        text_avg_vec[i] = np.zeros(100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPDOp-FDF1Ia","colab_type":"code","colab":{}},"source":["x_test = text_avg_vec\n","x_test = np.c_[x_test]\n","\n","df['label'] = df['label'] - 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aWBzII0F1Ic","colab_type":"code","colab":{}},"source":["#Logistic Regression Results\n","\n","predicted = lr.predict(x_test)\n","\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-MFxnsMbF1If","colab_type":"code","outputId":"b3e10d03-5ec1-4f3c-edd3-b49278b13a4a","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.84339836 0.85587053]\n","recall: [0.85837167 0.84068186]\n","fscore: [0.85081914 0.84820821]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zy4rr4qUF1Ik","colab_type":"code","outputId":"4ef95d11-642c-42c3-90a9-df0ccad3440b","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.849525\n","False pos: 0.0708\n","False neg: 0.079675\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xS_UTlNGF1In","colab_type":"code","colab":{}},"source":["#Naive Bayes Results\n","\n","predicted = clf.predict(x_test)\n","\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"51HmYgNcF1Iq","colab_type":"code","outputId":"7acaad1c-92b8-4421-f81f-1d4ffef900f8","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.72535\n","False pos: 0.14005\n","False neg: 0.1346\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hq9MOKkNF1Is","colab_type":"code","outputId":"adc1c3cf-4764-4648-ca9d-5e5088a5e9fc","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.72777834 0.72297498]\n","recall: [0.71984397 0.73085383]\n","fscore: [0.72378941 0.72689305]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WerwnNosF1Iu","colab_type":"code","colab":{}},"source":["#Deep neural network Results\n","\n","nn_model = tf.keras.models.load_model('NN.model')\n","predicted = nn_model.predict_classes(x_test)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfQ3hMytF1Iw","colab_type":"code","outputId":"d96bff4b-8230-4b0e-8ee1-fb3a22ce42ac","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.861675\n","False pos: 0.069775\n","False neg: 0.06855\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uewcIZN0F1Iy","colab_type":"code","outputId":"628013bb-70ab-4698-bef7-54d1c4985588","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.86253572 0.86081883]\n","recall: [0.86042208 0.86292741]\n","fscore: [0.86147761 0.86187183]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AOxM0zx0F1I1","colab_type":"code","colab":{}},"source":["#CNN Results\n","\n","x_test1 = x_test.reshape(40000, x_test.shape[1], 1)\n","\n","cnn_model = tf.keras.models.load_model('CNN.model')\n","predicted = cnn_model.predict_classes(x_test1)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"51lqmB38F1I3","colab_type":"code","outputId":"0b25e3e2-6b93-4ca4-e347-fb53adf58f6a","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.854125\n","False pos: 0.072325\n","False neg: 0.07355\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8Yyza72TF1I5","colab_type":"code","outputId":"df8f6b3e-1cbf-484c-8674-341eec3b0aac","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.85323023 0.8550238 ]\n","recall: [0.85532106 0.85292941]\n","fscore: [0.85427437 0.85397532]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v0EmOIWIF1I7","colab_type":"code","outputId":"5986c1bc-8a81-48b3-fa1d-8f99fd358cb2","colab":{}},"source":["#Training SVM\n","\n","from sklearn import svm\n","\n","svm_model = svm.SVC(kernel='linear')\n","\n","svm_model.fit(x_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n","    kernel='linear', max_iter=-1, probability=False, random_state=None,\n","    shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"-hu5y0uHF1I9","colab_type":"code","colab":{}},"source":["import pickle\n","# save the classifier\n","with open('svm_model.pkl', 'wb') as fid:\n","    pickle.dump(svm_model, fid)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQLQTQ4jF1JA","colab_type":"code","colab":{}},"source":["#SVM Results\n","\n","predicted = svm_model.predict(x_test)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyQmocGLF1JC","colab_type":"code","outputId":"cc98cd51-c86e-4ef3-bbd9-df71181235f2","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.849375\n","False pos: 0.071425\n","False neg: 0.0792\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LLscdhbuF1JE","colab_type":"code","outputId":"e0aaef82-9256-4441-c63c-052117482b5a","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.84399468 0.85492307]\n","recall: [0.85712142 0.84163167]\n","fscore: [0.85050741 0.84822531]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N81aqGhcF1JG","colab_type":"code","outputId":"ea601ee6-06ae-4cbe-af15-3b0a24ebc2e4","colab":{}},"source":["#Training Random Forest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_estimators=500, criterion='entropy', random_state=456)\n","\n","rf.fit(x_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=500,\n","                       n_jobs=None, oob_score=False, random_state=456,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"6MsQCBf3F1JI","colab_type":"code","colab":{}},"source":["#Random Forest Results\n","\n","predicted = rf.predict(x_test)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7TmpaMBF1JK","colab_type":"code","outputId":"4de1f2b1-d398-4fde-8ae5-cbf5aef2692d","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.832175\n","False pos: 0.078425\n","False neg: 0.0894\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WU-u8OMPF1JN","colab_type":"code","outputId":"b94f8431-f099-4157-b6f2-507cdb732d54","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support as score\n","\n","predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.82500612 0.83966266]\n","recall: [0.84311862 0.82123575]\n","fscore: [0.83396404 0.83034699]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hq2FXRCjF1JP","colab_type":"code","colab":{}},"source":["#Training second layer Random Forest (Combined models)\n","\n","lr_predict = lr.predict(x_train)\n","nb_predict = clf.predict(x_train)\n","svm_predict = svm_model.predict(x_train)\n","rf_predict = rf.predict(x_train)\n","nn_predict = nn_model.predict_classes(x_train)\n","cnn_predict = cnn_model.predict_classes(x_train1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YT_3kBqF1JS","colab_type":"code","outputId":"90ecedeb-a70c-4e94-e084-e73b35b7f571","colab":{}},"source":["new_features = pd.DataFrame()\n","new_features['lr_predict'] = lr_predict\n","new_features['nb_predict'] = nb_predict\n","new_features['svm_predict'] = svm_predict\n","new_features['rf_predict'] = rf_predict\n","new_features['nn_predict'] = nn_predict\n","new_features['cnn_predict'] = cnn_predict\n","\n","new_features.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_predict</th>\n","      <th>nb_predict</th>\n","      <th>svm_predict</th>\n","      <th>rf_predict</th>\n","      <th>nn_predict</th>\n","      <th>cnn_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n","0           0           0            0           0           0            0\n","1           1           1            1           1           1            1\n","2           1           0            1           0           1            1\n","3           1           1            1           1           1            1\n","4           1           0            1           1           1            1"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"bURoSX-wF1JU","colab_type":"code","outputId":"331a754d-14f5-4f4f-9eb9-11328852ca81","colab":{}},"source":["rf_2 = RandomForestClassifier(n_estimators=500, criterion='entropy')\n","\n","rf_2.fit(new_features, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=500,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"80WkqP51F1JW","colab_type":"code","colab":{}},"source":["#Combined model results (2nd layer Random Forest)\n","\n","lr_predict = lr.predict(x_test)\n","nb_predict = clf.predict(x_test)\n","svm_predict = svm_model.predict(x_test)\n","rf_predict = rf.predict(x_test)\n","nn_predict = nn_model.predict_classes(x_test)\n","cnn_predict = cnn_model.predict_classes(x_test1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIxEnxfQF1JY","colab_type":"code","outputId":"769539ec-cde6-403d-f71e-be09a01c3c6e","colab":{}},"source":["new_features = pd.DataFrame()\n","new_features['lr_predict'] = lr_predict\n","new_features['nb_predict'] = nb_predict\n","new_features['svm_predict'] = svm_predict\n","new_features['rf_predict'] = rf_predict\n","new_features['nn_predict'] = nn_predict\n","new_features['cnn_predict'] = cnn_predict\n","\n","new_features.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_predict</th>\n","      <th>nb_predict</th>\n","      <th>svm_predict</th>\n","      <th>rf_predict</th>\n","      <th>nn_predict</th>\n","      <th>cnn_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n","0           1           1            1           1           1            1\n","1           0           0            0           0           0            0\n","2           0           0            0           0           0            0\n","3           1           1            1           1           1            1\n","4           0           0            0           0           0            0"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"efQi8alRF1Ja","colab_type":"code","colab":{}},"source":["predicted = rf_2.predict(new_features)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLjwfpn0F1Jd","colab_type":"code","outputId":"ff52fff4-afdf-408e-d73a-1741fa971db5","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.832175\n","False pos: 0.078425\n","False neg: 0.0894\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KSsk_Uq3F1Jh","colab_type":"code","outputId":"25309aea-a722-479d-b107-65b3c6e1f4c0","colab":{}},"source":["predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.82500612 0.83966266]\n","recall: [0.84311862 0.82123575]\n","fscore: [0.83396404 0.83034699]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pROVhx4tF1Jl","colab_type":"code","outputId":"227207c0-b229-4d43-dc69-16943fbe6b09","colab":{}},"source":["#Trial: Training deep neural net as second layer (Combined models)\n","\n","lr_predict_train = lr.predict(x_train)\n","nb_predict_train = clf.predict(x_train)\n","svm_predict_train = svm_model.predict(x_train)\n","rf_predict_train = rf.predict(x_train)\n","nn_predict_train = nn_model.predict_classes(x_train)\n","cnn_predict_train = cnn_model.predict_classes(x_train1)\n","\n","new_features_train = pd.DataFrame()\n","new_features_train['lr_predict'] = lr_predict_train\n","new_features_train['nb_predict'] = nb_predict_train\n","new_features_train['svm_predict'] = svm_predict_train\n","new_features_train['rf_predict'] = rf_predict_train\n","new_features_train['nn_predict'] = nn_predict_train\n","new_features_train['cnn_predict'] = cnn_predict_train\n","\n","new_features_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lr_predict</th>\n","      <th>nb_predict</th>\n","      <th>svm_predict</th>\n","      <th>rf_predict</th>\n","      <th>nn_predict</th>\n","      <th>cnn_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n","0           0           0            0           0           0            0\n","1           1           1            1           1           1            1\n","2           1           0            1           0           1            1\n","3           1           1            1           1           1            1\n","4           1           0            1           1           1            1"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"0irBw0OEF1Jn","colab_type":"code","outputId":"268579ae-d997-45fd-b50d-b87a38ed137e","colab":{}},"source":["# mini batches Nadam optimizer with dropout and batch normalization\n","epochs = 10\n","model = tf.keras.Sequential()\n","model.add(layers.Dense(16, input_dim=6))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(16))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.2))\n","model.add(layers.Dense(16))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(32))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.3))\n","model.add(layers.Dense(32))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dense(32))\n","model.add(layers.Activation('relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.Dropout(rate = 0.4))\n","\n","model.add(layers.Dense(1))\n","model.add(layers.Activation('sigmoid'))\n","model.compile(loss='binary_crossentropy',\n","              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n","              metrics=['accuracy'])\n","checkpoint = keras.callbacks.ModelCheckpoint(\"NN2.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n","\n","model.summary()\n","model1 = model.fit(new_features_train, y_train, epochs=epochs, validation_split=0.2, callbacks=[checkpoint])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_34 (Dense)             (None, 16)                112       \n","_________________________________________________________________\n","activation_28 (Activation)   (None, 16)                0         \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 16)                64        \n","_________________________________________________________________\n","dense_35 (Dense)             (None, 16)                272       \n","_________________________________________________________________\n","activation_29 (Activation)   (None, 16)                0         \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 16)                64        \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 16)                0         \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 16)                272       \n","_________________________________________________________________\n","activation_30 (Activation)   (None, 16)                0         \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 16)                64        \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 32)                544       \n","_________________________________________________________________\n","activation_31 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_38 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","activation_32 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dense_39 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","activation_33 (Activation)   (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 32)                128       \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_40 (Dense)             (None, 1)                 33        \n","_________________________________________________________________\n","activation_34 (Activation)   (None, 1)                 0         \n","=================================================================\n","Total params: 3,921\n","Trainable params: 3,633\n","Non-trainable params: 288\n","_________________________________________________________________\n","WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n","Train on 96000 samples, validate on 24000 samples\n","Epoch 1/10\n","95840/96000 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9938\n","Epoch 00001: val_accuracy improved from -inf to 0.99996, saving model to NN2.model\n","INFO:tensorflow:Assets written to: NN2.model/assets\n","96000/96000 [==============================] - 26s 273us/sample - loss: 0.0192 - accuracy: 0.9938 - val_loss: 5.5018e-04 - val_accuracy: 1.0000\n","Epoch 2/10\n","95936/96000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n","Epoch 00002: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 22s 229us/sample - loss: 0.0026 - accuracy: 0.9996 - val_loss: 6.4392e-04 - val_accuracy: 1.0000\n","Epoch 3/10\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n","Epoch 00003: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 23s 236us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 6.4423e-04 - val_accuracy: 1.0000\n","Epoch 4/10\n","95872/96000 [============================>.] - ETA: 0s - loss: 8.0100e-04 - accuracy: 0.9999\n","Epoch 00004: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 23s 239us/sample - loss: 7.9994e-04 - accuracy: 0.9999 - val_loss: 6.4297e-04 - val_accuracy: 1.0000\n","Epoch 5/10\n","95840/96000 [============================>.] - ETA: 0s - loss: 1.8519e-04 - accuracy: 1.0000\n","Epoch 00005: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 23s 242us/sample - loss: 1.8491e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n","Epoch 6/10\n","95968/96000 [============================>.] - ETA: 0s - loss: 6.5417e-04 - accuracy: 0.9999\n","Epoch 00006: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 23s 239us/sample - loss: 6.5395e-04 - accuracy: 0.9999 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n","Epoch 7/10\n","95872/96000 [============================>.] - ETA: 0s - loss: 1.1154e-04 - accuracy: 1.0000\n","Epoch 00007: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 24s 251us/sample - loss: 1.1139e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n","Epoch 8/10\n","95872/96000 [============================>.] - ETA: 0s - loss: 2.8745e-04 - accuracy: 1.0000\n","Epoch 00008: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 24s 247us/sample - loss: 2.8707e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n","Epoch 9/10\n","95968/96000 [============================>.] - ETA: 0s - loss: 3.9127e-04 - accuracy: 1.0000\n","Epoch 00009: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 24s 250us/sample - loss: 3.9114e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n","Epoch 10/10\n","95776/96000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\n","Epoch 00010: val_accuracy did not improve from 0.99996\n","96000/96000 [==============================] - 24s 251us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RC0RNV-cF1Jr","colab_type":"code","outputId":"d57f7063-852c-4271-ee9e-2258c1b70a3e","colab":{}},"source":["#Combined model results (Deep Neural Net 2nd Layer)\n","\n","nn2_model = tf.keras.models.load_model('NN2.model')\n","predicted = nn2_model.predict_classes(new_features)\n","df['prediction'] = predicted"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0JD3bvyfF1Jt","colab_type":"code","outputId":"1ff3b0a5-8ea6-4942-e8c2-fd9b8165a3b7","colab":{}},"source":["count_true = 0\n","false_pos = 0\n","false_neg = 0\n","\n","for index, row in df.iterrows():\n","    if row['label'] == row['prediction']:\n","        count_true = count_true + 1\n","    elif row['label'] == 0 and row['prediction'] == 1:\n","        false_pos = false_pos + 1\n","    elif row['label'] == 1 and row['prediction'] == 0:\n","        false_neg = false_neg + 1\n","\n","print(\"Accuracy on test set: \" + str(count_true/len(df)))\n","print(\"False pos: \" + str(false_pos/len(df)))\n","print(\"False neg: \" + str(false_neg/len(df)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy on test set: 0.832175\n","False pos: 0.078425\n","False neg: 0.0894\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5K8etHSUF1Jw","colab_type":"code","outputId":"c02e5208-69f6-4d58-e861-5c5a4f3c8029","colab":{}},"source":["predicted = predicted \n","y_test = df['label']\n","\n","precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))\n","print('fscore: {}'.format(fscore))\n","print('support: {}'.format(support))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["precision: [0.82500612 0.83966266]\n","recall: [0.84311862 0.82123575]\n","fscore: [0.83396404 0.83034699]\n","support: [19996 20004]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPJT_R2BF1Jy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}